<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Examining the Influence of Opinionated Language Models during Writing.</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <!-- Additional CSS links if needed -->
</head>

<body>

    <div class="row pad10">
        <div class="content text">
            <div class="title">
                <a href="index.html" class="monospace">‚Üñ Home</a>
                <br>
                <img src="img/chischema.png" alt="Payment distribution at the end of the study"
                    class="projectImage projectHeaderImage">
            </div>

            <span class="strange-light">Examining the Influence of Opinionated Language Models during Writing.</span>
            </br>
            <!-- Increase space here -->
            <span style="display: inline-block; margin-top: 5px;">
                <a style="font-family: Notoicon; padding-right: 5px;">üè¢</a>
                <a href="https://s.tech.cornell.edu/" target="_blank" class="monospace">
                    sTech Lab, Cornell Tech, 2022-23
                </a>
            </span>

        </div>
    </div>

    <div class=" content text" style="display: flex; align-items: center;">
        <div style="flex: 1; text-align: center;">
            <span style="font-family:Notoicon, Arial, Helvetica, sans-serif; font-size: 2rem;">üìÉ</span>
        </div>
        <div style="flex: 9; padding: 10px;">
            <a class="pubLink" href="https://dl.acm.org/doi/abs/10.1145/3544548.3581196" target="_blank">Co-writing
                with Opinionated Language Models Affects Users‚Äô
                Views.</a>
            <br />
            <p style="margin-top:0px; margin-bottom:5px;">Maurice Jakesch, <span class="thisauthor">Advait Bhat</span>,
                Daniel
                Buschek, Lior Zalmanson, Mor Naaman„Éª</br>üèÜ
                <em>Best Paper Honourable Mention @ CHI‚Äô23</em>
            </p>

            <strong>How Co-writing with Opinionated Language Models Can Shape the
                Opinion Writing Process</strong>
            <br />
            <p style="margin-top:0px; margin-bottom:5px;"><span class="thisauthor">Advait Bhat</span>, Maurice Jakesch,
                Mor
                Naaman„Éª[ <em>Working Paper</em> ]
            </p>

            <!-- <strong>Bias in AI Autocomplete Suggestions Leads to Attitude Shift on
                Societal Issues</strong>
            <br />
            <p style="margin-top:0px; margin-bottom:5px;">Sterling Williams-Ceci, Maurice Jakesch,
                <span class="thisauthor">Advait Bhat</span>, Kowe Kadoma, Lior
                Zalmanson, Mor Naaman„Éª[ <em>In Submission</em> ]
            </p> -->
        </div>
    </div>
    <div class="content text" style="display: flex; align-items: center;">
        <div style="flex: 1; text-align: center;">
            <span class="gridTitle">my role</span>
        </div>
        <div style="flex: 9; padding: 10px; font-weight: 300">
            <em>Study design„Éªcontribution to interface design and development (tooling)„Éªmodel
                prompting„Éªinterviewing (protocol analysis)„Éªqualitative and quantitative analysis„Éªcomputational topic
                analysis„Éªpaper co-writing.</em>
        </div>
    </div>

    <!-- Overview Section -->
    <div class="row pad10">
        <div class="content text">
            <p class="has-dropcap">This project focuses on the influence of large language models like GPT on opinion
                formation and
                expression. It examines how these models, when configured to generate certain views more often, can
                affect users' written opinions and held beliefs. This overarching thread of research encompasses two
                studies:</p>

            <ol>
                <li><strong>Studying <em>if</em> opinionated language models shift the opinions writers express and
                        hold.</strong></li>
                <li><strong>Studying <em>possible mechanisms</em> and <em>theorising</em> about this influence through a
                        mixed
                        method approach.</strong></li>
            </ol>
            <img src="img/interfacechi.png" alt="Payment distribution at the end of the study" class="projectImage"
                style="border: 0px">
        </div>
    </div>


    <!-- study 1 Section -->
    <div class=" row pad10">
        <div class="content text">
            <span class="strange stretchable section">STUDY 1</span>
            <p style=" margin-top:0px">This study explores the concept of <strong>latent persuasion</strong>, where
                language models subtly influence opinions by making it easier to express certain views over others. This
                extends the idea of <strong>nudge theory</strong> to the field of language and persuasion. We designed
                and developed a
                ‚ÄòReddit-like‚Äô writing interface, where participants had to express their views on <strong>‚Äòis social
                    media good
                    or bad for society‚Äô</strong>. In an online experiment involving <strong>1506 participants</strong>,
                we examined whether
                interacting with a writing assistant powered by an opinionated language model would affect the opinions
                expressed in users' writings and subsequently alter their attitudes toward social media. Treatment group
                participants had to write with a writing assistant that either supported the position <strong>‚Äòsocial
                    media is
                    good for society‚Äô</strong> or opposed it.</p>

            <p>The results revealed that using an opinionated language model <strong>significantly influenced the
                    participants'
                    written opinions and shifted their attitudes in a follow-up survey</strong>. Participants
                interacting with a
                language model supportive of social media were more likely to express favorable views towards social
                media in both their writings and the survey. Conversely, those interacting with a model critical of
                social media expressed more negative views. This finding highlights the potential of <strong>AI language
                    technologies</strong> to shape public opinion and suggests a need for careful monitoring and
                engineering of the
                opinions embedded in these technologies.</p>

        </div>
    </div>
    <!-- Results Section -->
    <div class=" row pad10">
        <div class="content text"">
            <span class=" strange stretchable section">STUDY 2</span>
            <p style=" margin-top:0px">In this study, we used a mixed-method approach to investigate the mechanisms
                behind <strong>LM-induced influence</strong>, combining the interaction data from the first study with
                qualitative
                retrospective protocol interviews.</p>

            <p>We logged interactions in the text editor, capturing user and AI text, timestamps, and changes between
                states. Post-experiment, <strong>19 participants</strong> were interviewed. We used a custom tool to
                replay their writing
                process in order to elicit retrospective protocols from participants about their interactions with the
                AI assistant. Transcripts from the interviews were coded and analyzed systematically. The process
                involved <strong>open coding</strong>, <strong>memo writing</strong>, and <strong>thematic
                    analysis</strong>.</p>

            <p>Interaction logs were preprocessed to define "units" for analysis, each representing a sequence of
                writing done by the participants between two AI suggestions. We used <strong>GPT-3.5-Turbo</strong> for
                primary topic
                extraction from each text unit, followed by topic clustering using a <strong>BerTopic pipeline</strong>
                and <strong>hierarchical
                    agglomerative clustering</strong>. Finally, we conducted a <strong>temporal ‚Äòidea origin‚Äô
                    analysis</strong> to define whether a
                topic in the final composition was first proposed by the AI or the human participant. We labelled each
                unit as '<strong>AI-first</strong>' or '<strong>Human-first</strong>' based on the origin of the idea.
            </p>

            <p>The central finding of the study is the <strong>risk of a <em>‚Äòrole shift‚Äô</em> in the writing
                    process when using language
                    model-based assistants</strong>. This shift involves writers transforming from being primary idea
                generators to
                becoming <strong>'reactive' evaluators, editors, and extenders of AI-generated ideas</strong>. In this
                new role, writers
                often cede the initiative for generating original ideas to the language model, leading to a significant
                influence of AI on the writing process. This change marks a departure from traditional writing dynamics,
                where personal experiences and memories are the main sources of ideas. Instead, the AI's suggestions
                become the starting point, guiding and influencing the content and direction of the writer's output.
                This shift has profound implications for the creative process and the authorship of ideas in AI-assisted
                writing.</p>

            <p><strong>Shift in Writer's Role</strong>: Participants moved from expressing personal opinions based on
                experiences to primarily evaluating, editing, and extending AI-generated suggestions. Even when writers
                did not directly accept AI suggestions, this reactive approach anchored the ideas writers wrote about in
                AI suggestions.</p>

            <p><strong>AI's Dominance in Topic Initiation</strong>: A considerable portion of ideas in final
                compositions could be directly traced back to AI suggestions, with writers often accepting AI-generated
                ideas that they weren't initially planning to write about. This led to the AI predominantly setting the
                agenda for the topics discussed in the compositions.</p>

            <p><strong>AI's effect on topics written in writers' compositions</strong>: The AI assistant's stance (pro
                or anti-social media) affected the frequency of topics in its suggestions. This, in turn, influenced the
                topics covered in participants' writings, even in text not directly accepted from the AI. The AI's
                opinion bias significantly influenced the topics in participants' final compositions, confirming the
                AI's impact on shaping writers' topics and ideas.</p>

            <p><strong>Factors Leading to Reactive Writing</strong>:</p>

            <ul>
                <li><em>Effort Intensity</em>: Generating original ideas was more effort-intensive than evaluating AI
                    suggestions.</li>
                <li><em>Speed of AI Suggestions</em>: The AI's rapid suggestion generation outpaced participants' own
                    idea generation.</li>
                <li><em>Perceived AI Expertise</em>: Participants often accepted AI suggestions due to their
                    high-quality rhetoric and language, viewing the AI as an expert.</li>
                <li><em>Lack of Perceived Pressure</em>: Participants didn't feel pressured to accept AI suggestions,
                    contributing to their comfort in interacting with the AI.</li>
            </ul>

        </div>
    </div>
    <div class="row">
        <a class="content text" id="attr">
            ¬© Advait Bhat, 2023
    </div>

</body>

</html>